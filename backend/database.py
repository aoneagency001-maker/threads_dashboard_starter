"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö —Ü–∏—Ç–∞—Ç

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- SQLite (–ª–æ–∫–∞–ª—å–Ω–∞—è –±–∞–∑–∞)
- PostgreSQL/Supabase (–æ–±–ª–∞—á–Ω–∞—è –±–∞–∑–∞)
"""
import sqlite3
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import os

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass


class QuotesDatabase:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î —Ü–∏—Ç–∞—Ç"""

    def __init__(self, db_type: str = "sqlite", connection_string: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

        Args:
            db_type: –¢–∏–ø –ë–î ("sqlite" –∏–ª–∏ "postgres")
            connection_string: –°—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (–¥–ª—è postgres) –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (–¥–ª—è sqlite)
        """
        self.db_type = db_type

        if db_type == "sqlite":
            # SQLite: –ª–æ–∫–∞–ª—å–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
            if connection_string:
                self.db_path = connection_string
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: data/quotes.db
                base_dir = Path(__file__).resolve().parents[1]
                data_dir = base_dir / "data"
                data_dir.mkdir(exist_ok=True)
                self.db_path = str(data_dir / "quotes.db")

            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self.conn.row_factory = sqlite3.Row  # –í–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ª–æ–≤–∞—Ä–∏
            self._init_sqlite_schema()
            print(f"‚úÖ SQLite –±–∞–∑–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {self.db_path}")

        elif db_type == "postgres":
            # PostgreSQL/Supabase
            try:
                import psycopg2
                from psycopg2.extras import RealDictCursor

                if not connection_string:
                    connection_string = os.getenv("DATABASE_URL")

                if not connection_string:
                    raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL")

                self.conn = psycopg2.connect(connection_string, cursor_factory=RealDictCursor)
                self._init_postgres_schema()
                print(f"‚úÖ PostgreSQL –±–∞–∑–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
            except ImportError:
                raise ImportError("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ psycopg2: pip install psycopg2-binary")
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –ë–î: {db_type}")

    def _init_sqlite_schema(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è SQLite"""
        cursor = self.conn.cursor()

        # –¢–∞–±–ª–∏—Ü–∞ –∫–Ω–∏–≥
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS books (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                author TEXT,
                topic TEXT,
                file_path TEXT,
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                total_quotes INTEGER DEFAULT 0,
                metadata TEXT  -- JSON —Å –¥–æ–ø. –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            )
        """)

        # –¢–∞–±–ª–∏—Ü–∞ —Ü–∏—Ç–∞—Ç
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS quotes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                book_id INTEGER NOT NULL,
                page_number INTEGER,
                original_text TEXT,
                quote_text TEXT NOT NULL,
                translated_text TEXT,
                summary TEXT,

                -- –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
                category TEXT,
                style TEXT,
                target_audience TEXT,

                -- –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
                is_engaging BOOLEAN DEFAULT 0,
                quality_score REAL,
                completeness REAL,
                clarity REAL,
                practical_value REAL,

                -- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                length INTEGER,
                validation_level TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                published BOOLEAN DEFAULT 0,
                published_at TIMESTAMP,

                -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON
                metadata TEXT,

                FOREIGN KEY (book_id) REFERENCES books(id) ON DELETE CASCADE
            )
        """)

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_book_id ON quotes(book_id)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_category ON quotes(category)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_quality ON quotes(quality_score)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_published ON quotes(published)
        """)

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ (FTS5)
        cursor.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS quotes_fts USING fts5(
                quote_text,
                translated_text,
                summary,
                content='quotes',
                content_rowid='id'
            )
        """)

        self.conn.commit()

    def _init_postgres_schema(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è PostgreSQL"""
        cursor = self.conn.cursor()

        # –¢–∞–±–ª–∏—Ü–∞ –∫–Ω–∏–≥
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS books (
                id SERIAL PRIMARY KEY,
                title TEXT NOT NULL,
                author TEXT,
                topic TEXT,
                file_path TEXT,
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                total_quotes INTEGER DEFAULT 0,
                metadata JSONB
            )
        """)

        # –¢–∞–±–ª–∏—Ü–∞ —Ü–∏—Ç–∞—Ç
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS quotes (
                id SERIAL PRIMARY KEY,
                book_id INTEGER NOT NULL REFERENCES books(id) ON DELETE CASCADE,
                page_number INTEGER,
                original_text TEXT,
                quote_text TEXT NOT NULL,
                translated_text TEXT,
                summary TEXT,

                category TEXT,
                style TEXT,
                target_audience TEXT,

                is_engaging BOOLEAN DEFAULT FALSE,
                quality_score REAL,
                completeness REAL,
                clarity REAL,
                practical_value REAL,

                length INTEGER,
                validation_level TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                published BOOLEAN DEFAULT FALSE,
                published_at TIMESTAMP,

                metadata JSONB
            )
        """)

        # –ò–Ω–¥–µ–∫—Å—ã
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_book_id ON quotes(book_id)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_category ON quotes(category)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_quality ON quotes(quality_score)
        """)
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_metadata ON quotes USING GIN (metadata)
        """)

        # –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –¥–ª—è PostgreSQL
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_quotes_search
            ON quotes USING GIN (to_tsvector('russian', quote_text || ' ' || COALESCE(translated_text, '')))
        """)

        self.conn.commit()

    # ============================================
    # –ö–ù–ò–ì–ò
    # ============================================

    def add_book(self, title: str, author: str = "", topic: str = "",
                 file_path: str = "", metadata: Dict = None) -> int:
        """–î–æ–±–∞–≤–∏—Ç—å –∫–Ω–∏–≥—É –≤ –ë–î"""
        cursor = self.conn.cursor()

        if self.db_type == "sqlite":
            cursor.execute("""
                INSERT INTO books (title, author, topic, file_path, metadata)
                VALUES (?, ?, ?, ?, ?)
            """, (title, author, topic, file_path, json.dumps(metadata or {})))
            book_id = cursor.lastrowid
        else:  # postgres
            cursor.execute("""
                INSERT INTO books (title, author, topic, file_path, metadata)
                VALUES (%s, %s, %s, %s, %s)
                RETURNING id
            """, (title, author, topic, file_path, json.dumps(metadata or {})))
            book_id = cursor.fetchone()['id']

        self.conn.commit()
        return book_id

    def get_book(self, book_id: int) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–Ω–∏–≥—É –ø–æ ID"""
        cursor = self.conn.cursor()

        if self.db_type == "sqlite":
            cursor.execute("SELECT * FROM books WHERE id = ?", (book_id,))
        else:
            cursor.execute("SELECT * FROM books WHERE id = %s", (book_id,))

        row = cursor.fetchone()
        return dict(row) if row else None

    def get_book_by_title(self, title: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–Ω–∏–≥—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        cursor = self.conn.cursor()

        if self.db_type == "sqlite":
            cursor.execute("SELECT * FROM books WHERE title = ?", (title,))
        else:
            cursor.execute("SELECT * FROM books WHERE title = %s", (title,))

        row = cursor.fetchone()
        return dict(row) if row else None

    def list_books(self, limit: int = 100) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–Ω–∏–≥"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM books ORDER BY processed_at DESC LIMIT ?", (limit,))
        return [dict(row) for row in cursor.fetchall()]

    def update_book_stats(self, book_id: int):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–Ω–∏–≥–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∞—Ç)"""
        cursor = self.conn.cursor()

        if self.db_type == "sqlite":
            cursor.execute("""
                UPDATE books
                SET total_quotes = (SELECT COUNT(*) FROM quotes WHERE book_id = ?)
                WHERE id = ?
            """, (book_id, book_id))
        else:
            cursor.execute("""
                UPDATE books
                SET total_quotes = (SELECT COUNT(*) FROM quotes WHERE book_id = %s)
                WHERE id = %s
            """, (book_id, book_id))

        self.conn.commit()

    # ============================================
    # –¶–ò–¢–ê–¢–´
    # ============================================

    def add_quote(self, book_id: int, quote_data: Dict) -> int:
        """–î–æ–±–∞–≤–∏—Ç—å —Ü–∏—Ç–∞—Ç—É –≤ –ë–î"""
        cursor = self.conn.cursor()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        page_number = quote_data.get('page')
        original_text = quote_data.get('original', '')
        quote_text = quote_data.get('quote', '')
        translated_text = quote_data.get('translated', quote_text)
        summary = quote_data.get('summary', '')

        category = quote_data.get('category', 'general')
        style = quote_data.get('style', 'insight')
        target_audience = quote_data.get('target_audience', 'general')

        is_engaging = quote_data.get('engaging', False)
        meta = quote_data.get('meta', {})
        validation = quote_data.get('validation', {})

        quality_score = meta.get('confidence', validation.get('overall_score', 0.5))
        completeness = validation.get('completeness', meta.get('completeness', 0.0))
        clarity = validation.get('clarity', 0.0)
        practical_value = validation.get('practical_value', meta.get('practical_value', 0.0))

        length = len(quote_text)
        validation_level = validation.get('validation_level', 'basic')

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        all_metadata = {**meta, **validation, 'original_data': quote_data}

        if self.db_type == "sqlite":
            cursor.execute("""
                INSERT INTO quotes (
                    book_id, page_number, original_text, quote_text, translated_text, summary,
                    category, style, target_audience,
                    is_engaging, quality_score, completeness, clarity, practical_value,
                    length, validation_level, metadata
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                book_id, page_number, original_text, quote_text, translated_text, summary,
                category, style, target_audience,
                is_engaging, quality_score, completeness, clarity, practical_value,
                length, validation_level, json.dumps(all_metadata)
            ))
            quote_id = cursor.lastrowid
        else:  # postgres
            cursor.execute("""
                INSERT INTO quotes (
                    book_id, page_number, original_text, quote_text, translated_text, summary,
                    category, style, target_audience,
                    is_engaging, quality_score, completeness, clarity, practical_value,
                    length, validation_level, metadata
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                book_id, page_number, original_text, quote_text, translated_text, summary,
                category, style, target_audience,
                is_engaging, quality_score, completeness, clarity, practical_value,
                length, validation_level, json.dumps(all_metadata)
            ))
            quote_id = cursor.fetchone()['id']

        self.conn.commit()
        return quote_id

    def get_quotes(self, book_id: Optional[int] = None,
                   category: Optional[str] = None,
                   min_quality: float = 0.0,
                   only_engaging: bool = False,
                   only_unpublished: bool = False,
                   limit: int = 100,
                   offset: int = 0) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ü–∏—Ç–∞—Ç—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

        Args:
            book_id: ID –∫–Ω–∏–≥–∏ (None = –≤—Å–µ –∫–Ω–∏–≥–∏)
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ü–∏—Ç–∞—Ç
            min_quality: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –∫–∞—á–µ—Å—Ç–≤–∞
            only_engaging: –¢–æ–ª—å–∫–æ engaging —Ü–∏—Ç–∞—Ç—ã
            only_unpublished: –¢–æ–ª—å–∫–æ –Ω–µ–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            offset: –°–º–µ—â–µ–Ω–∏–µ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        """
        cursor = self.conn.cursor()

        conditions = []
        params = []

        if book_id:
            conditions.append("book_id = ?")
            params.append(book_id)

        if category:
            conditions.append("category = ?")
            params.append(category)

        if min_quality > 0:
            conditions.append("quality_score >= ?")
            params.append(min_quality)

        if only_engaging:
            conditions.append("is_engaging = 1")

        if only_unpublished:
            conditions.append("published = 0")

        where_clause = " AND ".join(conditions) if conditions else "1=1"

        query = f"""
            SELECT * FROM quotes
            WHERE {where_clause}
            ORDER BY quality_score DESC, created_at DESC
            LIMIT ? OFFSET ?
        """

        params.extend([limit, offset])

        if self.db_type == "postgres":
            query = query.replace("?", "%s")

        cursor.execute(query, params)

        quotes = []
        for row in cursor.fetchall():
            quote_dict = dict(row)
            # –ü–∞—Ä—Å–∏–º JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if 'metadata' in quote_dict and quote_dict['metadata']:
                try:
                    quote_dict['metadata'] = json.loads(quote_dict['metadata'])
                except:
                    pass
            quotes.append(quote_dict)

        return quotes

    def search_quotes(self, search_text: str, limit: int = 50) -> List[Dict]:
        """–ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ü–∏—Ç–∞—Ç–∞–º"""
        cursor = self.conn.cursor()

        if self.db_type == "sqlite":
            # FTS5 –ø–æ–∏—Å–∫
            cursor.execute("""
                SELECT quotes.* FROM quotes
                JOIN quotes_fts ON quotes.id = quotes_fts.rowid
                WHERE quotes_fts MATCH ?
                ORDER BY rank
                LIMIT ?
            """, (search_text, limit))
        else:  # postgres
            # PostgreSQL full-text search
            cursor.execute("""
                SELECT * FROM quotes
                WHERE to_tsvector('russian', quote_text || ' ' || COALESCE(translated_text, ''))
                      @@ plainto_tsquery('russian', %s)
                ORDER BY quality_score DESC
                LIMIT %s
            """, (search_text, limit))

        return [dict(row) for row in cursor.fetchall()]

    def mark_as_published(self, quote_id: int):
        """–û—Ç–º–µ—Ç–∏—Ç—å —Ü–∏—Ç–∞—Ç—É –∫–∞–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—É—é"""
        cursor = self.conn.cursor()

        if self.db_type == "sqlite":
            cursor.execute("""
                UPDATE quotes
                SET published = 1, published_at = CURRENT_TIMESTAMP
                WHERE id = ?
            """, (quote_id,))
        else:
            cursor.execute("""
                UPDATE quotes
                SET published = TRUE, published_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, (quote_id,))

        self.conn.commit()

    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        cursor = self.conn.cursor()

        stats = {}

        # –í—Å–µ–≥–æ –∫–Ω–∏–≥
        cursor.execute("SELECT COUNT(*) as count FROM books")
        stats['total_books'] = cursor.fetchone()['count']

        # –í—Å–µ–≥–æ —Ü–∏—Ç–∞—Ç
        cursor.execute("SELECT COUNT(*) as count FROM quotes")
        stats['total_quotes'] = cursor.fetchone()['count']

        # –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ü–∏—Ç–∞—Ç
        cursor.execute("SELECT COUNT(*) as count FROM quotes WHERE published = ?", (1 if self.db_type == "sqlite" else True,))
        stats['published_quotes'] = cursor.fetchone()['count']

        # –°—Ä–µ–¥–Ω–∏–π –∫–∞—á–µ—Å—Ç–≤–∞
        cursor.execute("SELECT AVG(quality_score) as avg FROM quotes")
        stats['avg_quality'] = cursor.fetchone()['avg'] or 0.0

        # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        cursor.execute("""
            SELECT category, COUNT(*) as count
            FROM quotes
            GROUP BY category
            ORDER BY count DESC
        """)
        stats['by_category'] = {row['category']: row['count'] for row in cursor.fetchall()}

        return stats

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ"""
        if self.conn:
            self.conn.close()
            print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å (—Å–∏–Ω–≥–ª—Ç–æ–Ω)
_global_db: Optional[QuotesDatabase] = None


def get_db(db_type: str = "sqlite", connection_string: Optional[str] = None) -> QuotesDatabase:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å –ë–î"""
    global _global_db

    if _global_db is None:
        _global_db = QuotesDatabase(db_type, connection_string)

    return _global_db


def reset_db():
    """–°–±—Ä–æ—Å–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å"""
    global _global_db
    if _global_db:
        _global_db.close()
        _global_db = None


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    # –°–æ–∑–¥–∞—ë–º –ë–î
    db = get_db("sqlite")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∫–Ω–∏–≥—É
    book_id = db.add_book(
        title="DotCom Secrets",
        author="Russell Brunson",
        topic="–º–∞—Ä–∫–µ—Ç–∏–Ω–≥",
        metadata={"pages": 250}
    )
    print(f"‚úÖ –ö–Ω–∏–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞: ID={book_id}")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Ü–∏—Ç–∞—Ç—É
    quote_id = db.add_quote(book_id, {
        "page": 42,
        "quote": "–õ—É—á—à–∏–π –ø—Ä–æ–¥—É–∫—Ç –Ω–µ –ø–æ–±–µ–∂–¥–∞–µ—Ç. –ü–æ–±–µ–∂–¥–∞–µ—Ç –ª—É—á—à–∏–π –º–∞—Ä–∫–µ—Ç–∏–Ω–≥.",
        "translated": "–õ—É—á—à–∏–π –ø—Ä–æ–¥—É–∫—Ç –Ω–µ –ø–æ–±–µ–∂–¥–∞–µ—Ç. –ü–æ–±–µ–∂–¥–∞–µ—Ç –ª—É—á—à–∏–π –º–∞—Ä–∫–µ—Ç–∏–Ω–≥.",
        "summary": "–í–∞–∂–Ω–æ—Å—Ç—å –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞ –Ω–∞–¥ –∫–∞—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–¥—É–∫—Ç–∞",
        "category": "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥",
        "engaging": True,
        "meta": {"confidence": 0.95}
    })
    print(f"‚úÖ –¶–∏—Ç–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞: ID={quote_id}")

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = db.get_stats()
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –ö–Ω–∏–≥: {stats['total_books']}")
    print(f"   –¶–∏—Ç–∞—Ç: {stats['total_quotes']}")
    print(f"   –°—Ä–µ–¥–Ω–∏–π –∫–∞—á–µ—Å—Ç–≤–∞: {stats['avg_quality']:.2f}")

    # –ü–æ–ª—É—á–∞–µ–º —Ü–∏—Ç–∞—Ç—ã
    quotes = db.get_quotes(book_id=book_id)
    print(f"\nüìù –¶–∏—Ç–∞—Ç –Ω–∞–π–¥–µ–Ω–æ: {len(quotes)}")
    for q in quotes:
        print(f"   - {q['quote_text'][:60]}...")

    db.close()
