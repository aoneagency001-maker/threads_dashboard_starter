"""
–ì–ª—É–±–æ–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –í–°–ï–• –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –∫–Ω–∏–≥–∏ —Å –ø–æ–º–æ—â—å—é Google Gemini.

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Gemini:
- –û–≥—Ä–æ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: –¥–æ 2M —Ç–æ–∫–µ–Ω–æ–≤ (—Ü–µ–ª–∞—è –∫–Ω–∏–≥–∞ –∑–∞ —Ä–∞–∑!)
- –û—á–µ–Ω—å –¥–µ—à–µ–≤–æ: $0.075 / 1M –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
- –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–∏—Ç–∞—Ç
"""

import os
import json
from typing import List, Dict, Any
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()

class GeminiDeepExtractor:
    """–ì–ª—É–±–æ–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –∫–Ω–∏–≥ —Å –ø–æ–º–æ—â—å—é Gemini"""

    def __init__(self, api_key: str = None):
        """
        Args:
            api_key: Gemini API –∫–ª—é—á (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ .env)
        """
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("Gemini API key not found. Add GEMINI_API_KEY to .env file")

        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    def extract_all_insights_from_text(self, full_text: str, book_title: str = "") -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –í–°–ï —Ü–µ–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏–∑ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫–Ω–∏–≥–∏ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å.

        Args:
            full_text: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–Ω–∏–≥–∏
            book_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ü–∏—Ç–∞—Ç/–∏–Ω—Å–∞–π—Ç–æ–≤
        """
        print(f"üìö –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–Ω–∏–≥–∏ —Å Gemini...")
        print(f"üìÑ –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        system_prompt = """
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —Ü–µ–Ω–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –±–∏–∑–Ω–µ—Å-–∫–Ω–∏–≥ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª–µ–π –∏ –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥–æ–≤.

üéØ –¢–í–û–Ø –ó–ê–î–ê–ß–ê: –ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Ü–µ–Ω–Ω—ã–µ –º—ã—Å–ª–∏, –∏–Ω—Å–∞–π—Ç—ã –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –∏–∑ —ç—Ç–æ–π –∫–Ω–∏–≥–∏.

üìä –ß–¢–û –ò–ó–í–õ–ï–ö–ê–¢–¨:
1. –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
2. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
3. –ü—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã
4. –í–∞–∂–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∏ —Ç–µ–∑–∏—Å—ã
5. Actionable –∏–Ω—Å–∞–π—Ç—ã (—á—Ç–æ –º–æ–∂–Ω–æ –≤–Ω–µ–¥—Ä–∏—Ç—å)
6. –¶–∏—Ç–∞—Ç—ã —Å –≤—ã—Å–æ–∫–æ–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç—å—é

‚ùå –ß–¢–û –ù–ï –ò–ó–í–õ–ï–ö–ê–¢–¨:
- –û–≥–ª–∞–≤–ª–µ–Ω–∏—è –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≥–ª–∞–≤
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∏ —Å–Ω–æ—Å–∫–∏
- –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–¥–∏—Å–ª–æ–≤–∏—è
- –°—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
- –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –º—ã—Å–ª–∏

üìè –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ö–ê–ñ–î–û–ô –¶–ò–¢–ê–¢–ï:
- –î–ª–∏–Ω–∞: 50-500 —Å–∏–º–≤–æ–ª–æ–≤ (–¥–ª—è Threads)
- –ü–û–õ–ù–ê–Ø –∑–∞–∫–æ–Ω—á–µ–Ω–Ω–∞—è –º—ã—Å–ª—å
- –ü–æ–Ω—è—Ç–Ω–∞ –ë–ï–ó –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–Ω–∏–≥–∏
- –ò–º–µ–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å
- –ó–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π/!/?

üé® –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê - —Å—Ç—Ä–æ–≥–æ JSON:
{
  "quotes": [
    {
      "quote": "–¢–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã (–≥–æ—Ç–æ–≤–æ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Threads)",
      "summary": "–ö—Ä–∞—Ç–∫–∞—è —Å—É—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º",
      "category": "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥|–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è|–ø—Ä–æ–¥–∞–∂–∏|–º—ã—à–ª–µ–Ω–∏–µ|—Ñ–∏–Ω–∞–Ω—Å—ã|–ª–∏–¥–µ—Ä—Å—Ç–≤–æ",
      "style": "insight|rule|mistake|observation|example|principle",
      "practical_value": 0.0-1.0,
      "engaging_score": 0.0-1.0,
      "page_hint": "–ø—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏–ª–∏ —Ä–∞–∑–¥–µ–ª"
    },
    ...
  ]
}

üí° –°–¢–†–ê–¢–ï–ì–ò–Ø:
1. –ü—Ä–æ—á–∏—Ç–∞–π –í–ï–°–¨ —Ç–µ–∫—Å—Ç –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ
2. –ù–∞–π–¥–∏ –í–°–ï –∑–Ω–∞—á–∏–º—ã–µ –º—ã—Å–ª–∏ (–Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π —Å–µ–±—è)
3. –û—Ç–±–µ—Ä–∏ 50-200 –ª—É—á—à–∏—Ö —Ü–∏—Ç–∞—Ç (—á–µ–º –±–æ–ª—å—à–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö, —Ç–µ–º –ª—É—á—à–µ)
4. –£–±–µ–¥–∏—Å—å —á—Ç–æ –∫–∞–∂–¥–∞—è —Ü–∏—Ç–∞—Ç–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–∞—è –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è
5. –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–π –ø–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
"""

        user_prompt = f"""
–ö–Ω–∏–≥–∞: {book_title if book_title else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"}

–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢ –ö–ù–ò–ì–ò:
{full_text[:500000]}  # Gemini –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ 2M —Ç–æ–∫–µ–Ω–æ–≤!

–ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Ü–µ–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏–∑ —ç—Ç–æ–π –∫–Ω–∏–≥–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
"""

        try:
            print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å Gemini (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-60 —Å–µ–∫—É–Ω–¥)...")

            response = self.model.generate_content(
                [system_prompt, user_prompt],
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=16384,  # –ú–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞
                )
            )

            # –ü–∞—Ä—Å–∏–º JSON
            response_text = response.text.strip()

            # –£–±–∏—Ä–∞–µ–º markdown –æ–±–µ—Ä—Ç–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]

            response_text = response_text.strip()

            data = json.loads(response_text)
            quotes_list = data.get("quotes", [])

            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(quotes_list)} —Ü–∏—Ç–∞—Ç!")

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            processed_quotes = []
            for idx, quote_data in enumerate(quotes_list, 1):
                processed = {
                    "quote": quote_data.get("quote", "").strip(),
                    "translated": quote_data.get("quote", "").strip(),  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    "summary": quote_data.get("summary", ""),
                    "category": quote_data.get("category", "–º—ã—à–ª–µ–Ω–∏–µ"),
                    "style": quote_data.get("style", "insight"),
                    "engaging": quote_data.get("engaging_score", 0.5) > 0.6,
                    "meta": {
                        "practical_value": quote_data.get("practical_value", 0.7),
                        "engaging_score": quote_data.get("engaging_score", 0.7),
                        "page_hint": quote_data.get("page_hint", ""),
                        "extraction_method": "gemini_deep_scan",
                        "quote_index": idx,
                        "length": len(quote_data.get("quote", ""))
                    }
                }

                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ –¥–ª–∏–Ω–Ω—ã–µ
                if 30 <= len(processed["quote"]) <= 500:
                    processed_quotes.append(processed)

            print(f"üìä –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(processed_quotes)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ü–∏—Ç–∞—Ç")

            return processed_quotes

        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {response_text[:500]}")
            return []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏: {e}")
            return []

    def extract_from_pdf_deep_scan(
        self,
        pdf_path: str,
        output_json_path: str = None
    ) -> str:
        """
        –ü–æ–ª–Ω–æ–µ –≥–ª—É–±–æ–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ PDF –∫–Ω–∏–≥–∏.

        Args:
            pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
            output_json_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Returns:
            –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        from . import parser as book_parser

        print(f"\n{'='*60}")
        print(f"üöÄ –ì–õ–£–ë–û–ö–û–ï –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï –ö–ù–ò–ì–ò –° GEMINI")
        print(f"{'='*60}\n")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ PDF
        print("üìñ –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF...")
        pages = book_parser.extract_pages_from_pdf(pdf_path)
        full_text = "\n\n".join([
            book_parser.clean_text(page)
            for page in pages
        ])

        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")
        print(f"üìä –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(full_text):,}")

        # –ì–ª—É–±–æ–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å Gemini
        print(f"\nüîç –®–∞–≥ 2: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å Gemini AI...")
        book_title = Path(pdf_path).stem
        all_quotes = self.extract_all_insights_from_text(full_text, book_title)

        if not all_quotes:
            print("‚ö†Ô∏è –¶–∏—Ç–∞—Ç—ã –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã")
            return ""

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüíæ –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

        if output_json_path:
            out_path = Path(output_json_path)
        else:
            base_dir = Path(__file__).resolve().parents[1]
            quotes_dir = base_dir / "data" / "quotes"
            quotes_dir.mkdir(parents=True, exist_ok=True)
            out_path = quotes_dir / (book_title.replace(" ", "-") + "_deep.json")

        payload = {
            "book": book_title,
            "extraction_method": "gemini_deep_scan",
            "total_pages": len(pages),
            "total_chars": len(full_text),
            "total_quotes": len(all_quotes),
            "quotes": all_quotes
        }

        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {out_path}")

        print(f"\n{'='*60}")
        print(f"üéâ –ì–õ–£–ë–û–ö–û–ï –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"{'='*60}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   ‚Ä¢ –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(pages)}")
        print(f"   ‚Ä¢ –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ü–∏—Ç–∞—Ç: {len(all_quotes)}")
        print(f"   ‚Ä¢ –û—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö: {len([q for q in all_quotes if q.get('engaging')])}")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {sum(len(q['quote']) for q in all_quotes) // len(all_quotes)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"{'='*60}\n")

        return str(out_path)
